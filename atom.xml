<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ClT&#39;s Blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2016-04-20T10:37:49.309Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ClT</name>
    <email>cl.tian@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习(11)</title>
    <link href="http://yoursite.com/2016/04/20/ML11/"/>
    <id>http://yoursite.com/2016/04/20/ML11/</id>
    <published>2016-04-20T07:46:05.000Z</published>
    <updated>2016-04-20T10:37:49.309Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习-11&quot;&gt;&lt;a href=&quot;#机器学习-11&quot; class=&quot;headerlink&quot; title=&quot;机器学习 11&quot;&gt;&lt;/a&gt;机器学习 11&lt;/h1&gt;&lt;p&gt;Gaussian Discriminant Analysis(GDA)是最基本的一类生成式模型，用于分类。假设某一类别的数据服从Gaussian，类别的出现服从Bern分布，则：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.20.1.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;实际的优化问题与距离相关，所以这可以看做一种kNN学习。&lt;/p&gt;
&lt;p&gt;参数估计出来之后，posterior就可以轻易得到：&lt;/p&gt;
&lt;p&gt;对于多分类，如果x|y的cov不相同，则称为Quadratic discriminant analysis(QDA)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.20.2.png&quot; height=&quot;60&quot;&gt;&lt;/p&gt;
&lt;p&gt;式子很复杂，数学家喜欢看着优美点的，考虑特殊情况x|y的cov相同，此时是Linear discriminant analysis(LDA)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.20.3.png&quot; height=&quot;90&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意到，Bayes Theorem的归一化分母没有写。如果添加上，会发现：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.20.4.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;这是源于热力学的归一化的Boltzmann函数，也就是Boltzmann分布，其实也是多分类的sigmoid的函数。至于，为什么叫做LDA也是很明确的，因为含有线性scoring。QDA的分子分母无法化简，表现为二次scoring。&lt;/p&gt;
&lt;p&gt;其实刚才已经言明，二分类LDA相似于LogReg，LDA也具备kNN这类惰性学习算法的特点。&lt;/p&gt;
&lt;p&gt;再从统计学的角度来看LDA，也就是著名的Fisher’s linear discriminant(FLD)，这个方法是由著名统计学家Fisher提出的，时间早于lDA，但是却有惊人的相似。&lt;/p&gt;
&lt;p&gt;FLD不依赖于分布函数和Bayes方法，更像是一种判别式方案。线性判别式模式识别常见的任务，等价于机器学习的分类，但是不一定用学习的方法。普通的线性判别有一个很大的问题：高维和低维的不一致性。高维数据和低维数据的判别超平面是不一样的。那么如何让高维和低维统一起来呢？作为统计学家的Fisher提出了基于统计学的方法。&lt;/p&gt;
&lt;p&gt;我们先考虑2维线性判别，它的思想很朴素：将数据投影到一条直线上，使得同类数据尽可能近，异类数据尽可能远。做一下简单的推导，定义两个类别的均值和协方差，则均值和协方差在分界线上的值分别为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.20.5.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;此时，希望异类的均值距离远，同类的协方差尽可能近：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.20.6.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个优化问题等于广义Rayleigh商：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.20.7.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;多分类的FLD类似于二分类的FLD。&lt;/p&gt;
&lt;p&gt;LDA不仅可以用于分类，还可以用于降维。注意只要学习出w，那么可以把N维数据投影到N-1维空间。&lt;/p&gt;
&lt;p&gt;为什么说FLD和LDA殊途同归呢？考虑最上面的式子，我们说等同于kNN，也就是类内间距足够小。类间间距由y的prior决定。所以，结论是LDA=FLD，他们和kNN，LogReg相似。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习-11&quot;&gt;&lt;a href=&quot;#机器学习-11&quot; class=&quot;headerlink&quot; title=&quot;机器学习 11&quot;&gt;&lt;/a&gt;机器学习 11&lt;/h1&gt;&lt;p&gt;Gaussian Discriminant Analysis(GDA)是最基本的一类生成式模型，用于
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>几个优化算法小程序</title>
    <link href="http://yoursite.com/2016/04/16/coding1/"/>
    <id>http://yoursite.com/2016/04/16/coding1/</id>
    <published>2016-04-16T08:46:05.000Z</published>
    <updated>2016-04-20T10:40:01.629Z</updated>
    
    <content type="html">&lt;h1 id=&quot;几个优化算法小程序&quot;&gt;&lt;a href=&quot;#几个优化算法小程序&quot; class=&quot;headerlink&quot; title=&quot;几个优化算法小程序&quot;&gt;&lt;/a&gt;几个优化算法小程序&lt;/h1&gt;&lt;p&gt;写了几个maltab版的无约束优化计算程序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wolfe非精确线搜索步长求解&lt;/li&gt;
&lt;li&gt;Armjio非精确线搜索步长求解&lt;/li&gt;
&lt;li&gt;GD法求解非约束优化&lt;/li&gt;
&lt;li&gt;Newton法求解非约束优化&lt;/li&gt;
&lt;li&gt;BFGS quasi-Newton法求解非约束优化&lt;/li&gt;
&lt;li&gt;CG法求解非约束优化&lt;/li&gt;
&lt;li&gt;使用差分法求解Gradient和Hessian&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于都是简单的程序，计算速度不快。另外CG法的precondioning没做，LBFGS没做，Newton法是最原始的版本,所以经常会出问题。&lt;/p&gt;
&lt;p&gt;接下来，希望把LBFGS搞出来，简单的约束优化方法也准备弄出来。python版本也准备开发。&lt;/p&gt;
&lt;p&gt;&lt;s&gt;使用范例：[x,y]=tGD(@funName, w0, varargin)&lt;/s&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Codes are in my github, welcome pulling request&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;s&gt;&lt;strong&gt;采用100*2的feature，对Logistic回归做了一下数值模拟&lt;/strong&gt;，统计了一下错误率和训练时间(s)：&lt;/s&gt;&lt;/p&gt;
&lt;p&gt;&lt;s&gt;GD+Armijo  12%  0.3&lt;/s&gt;&lt;br&gt;&lt;s&gt;GD+Wolfe    14%  4.7&lt;/s&gt;&lt;/p&gt;
&lt;p&gt;&lt;s&gt;Newton+Armijo NaN：原因是Hessian条件数太差&lt;/s&gt;&lt;br&gt;&lt;s&gt;Newton+Wolfe  17% 17&lt;/s&gt;&lt;/p&gt;
&lt;p&gt;&lt;s&gt;CG+Armijo 16%  0.11&lt;/s&gt;&lt;br&gt;&lt;s&gt;CG+Wolfe   9%    0.35&lt;/s&gt;&lt;/p&gt;
&lt;p&gt;&lt;s&gt;BFGS+Armijo 7%    0.04&lt;/s&gt;&lt;br&gt;&lt;s&gt;BFGS+Wolfe  2.4%  0.03&lt;/s&gt;&lt;/p&gt;
&lt;p&gt;&lt;s&gt;GD+Wolfe训练时间长且错误率高；Newton+Armijo有时可能无法训练出结果，原始Newton法非常慢；BFGS效果最好。&lt;/s&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt;(Apr. 18)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;改进原始Newton法为damped modified Newton法&lt;/li&gt;
&lt;li&gt;添加LBFGS&lt;/li&gt;
&lt;li&gt;接口改变，可以设置参数&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;eg:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;options.method=’BFGS’;&lt;br&gt;options.nmax=1000;&lt;br&gt;[x,y1,time,niter]=tmin(f,x0,options,X,y);&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;数值模拟：10000*2 feature，Logistic分类&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.18.1.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;顺便试了一下SGD，发现几分钟都运行不出来，偶尔会非常快。估计主要原因是SGD等同于直接迭代，在具有数值优化功能的软件比较慢，在C一类的语言中，估计和GD差不多，但是写着简单点。&lt;/p&gt;
&lt;p&gt;小规模精确求解BFGS最好，大规模LBFGS较好。LBFGS错误率虽然有点高，但是时间优势太大。Newton法本来应该比CG法块，但是计算Hessian花了太多的时间。&lt;/p&gt;
&lt;p&gt;&lt;b&gt;&lt;strong&gt;UPDATE(Apr.20):&lt;/strong&gt;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;已知对LBFGS的误差耿耿于怀，研究了一下，找到了问题。LogReg的训练很容易产生underflow，进而得到NaN的结果，原来也发现，然后加了一个0.01的bias。但是估计LBFGS算法本身会抛掉一些Sample，以节省内存，把bias放大了。不论调什么参数都没办法降低err。看了一下MLPP，发现可以使用log-sum-exp trick解决，试了一下，发现LBFGS错误率大大降低。&lt;/p&gt;
&lt;p&gt;使用100000*5的样本训练：&lt;/p&gt;
&lt;p&gt;LBFGS：用时0.96s，5000次迭代，错误率12.21%&lt;/p&gt;
&lt;p&gt;BFGS：用时4.625s，12次迭代，错误率10.78%&lt;/p&gt;
&lt;p&gt;另几个算法，这个规模的数据几分钟都算不出来，降低数据规模10000*5：&lt;/p&gt;
&lt;p&gt;Newton：用时37.28s，269次迭代，错误率5.42%&lt;/p&gt;
&lt;p&gt;CG：用时92.34s，2500次迭代，错误率11.22%&lt;/p&gt;
&lt;p&gt;GD：用时104.82s，2500次迭代，错误率5.74%&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;几个优化算法小程序&quot;&gt;&lt;a href=&quot;#几个优化算法小程序&quot; class=&quot;headerlink&quot; title=&quot;几个优化算法小程序&quot;&gt;&lt;/a&gt;几个优化算法小程序&lt;/h1&gt;&lt;p&gt;写了几个maltab版的无约束优化计算程序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wolfe非
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(10)</title>
    <link href="http://yoursite.com/2016/04/14/ML10/"/>
    <id>http://yoursite.com/2016/04/14/ML10/</id>
    <published>2016-04-14T15:46:05.000Z</published>
    <updated>2016-04-16T08:49:24.057Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习10&quot;&gt;&lt;a href=&quot;#机器学习10&quot; class=&quot;headerlink&quot; title=&quot;机器学习10&quot;&gt;&lt;/a&gt;机器学习10&lt;/h1&gt;&lt;h2 id=&quot;1-Boosting&quot;&gt;&lt;a href=&quot;#1-Boosting&quot; class=&quot;headerlink&quot; title=&quot;1.Boosting&quot;&gt;&lt;/a&gt;1.Boosting&lt;/h2&gt;&lt;p&gt;和bagging相似，这也是一种针对样本的multi-stage，不同的是，Boosting采用串行策略，适用于个体学习器之间存在强依赖关系。Boosting不采用Bootstrap sampling的方法，而是根据学习器的表现对训练样本的分布进行调整。让学习错误的base learner受到关注，让学习正确的base learner减少关注。&lt;/p&gt;
&lt;p&gt;Boosting方法中最著名的是AdaBoost(Adaptive Boosting):&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.1.png&quot; width=&quot;400&quot; height=&quot;300&quot;&gt;&lt;/p&gt;
&lt;p&gt;AdaBoost确实完成了我们的想法，“对不同的孩子给予了不同的照顾”。&lt;/p&gt;
&lt;h2 id=&quot;2-Functional-amp-Optimization-Viewpoint-Of-Boosting&quot;&gt;&lt;a href=&quot;#2-Functional-amp-Optimization-Viewpoint-Of-Boosting&quot; class=&quot;headerlink&quot; title=&quot;2.Functional &amp;amp; Optimization Viewpoint Of Boosting&quot;&gt;&lt;/a&gt;2.Functional &amp;amp; Optimization Viewpoint Of Boosting&lt;/h2&gt;&lt;p&gt;上面的语言有点直观，这里将采用泛函与优化的角度说明Boosting方法。&lt;/p&gt;
&lt;p&gt;在LM中，我们一直在学习参数，具体来说是w，也就是优化这个参数。常采用的是GD或SGD法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.4.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;在Boosting中，我们并不知道base learner是什么，这里优化的不是参数，而是函数。在函数空间找到最优的函数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.2.png&quot; width=&quot;150&quot; height=&quot;50&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个时候当然GD法会改一改，但是框架不变：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.5.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们进行迭代算法的目标仍然是最优化“步长”和“方向”。采用exp-loss：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.6.png&quot; height=&quot;60&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于二分类（+1/-1）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.7.png&quot; height=&quot;110&quot;&gt;&lt;/p&gt;
&lt;p&gt;最优化“步长”（steppest descent):&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.9.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;接下来最优化“方向”。再认真观察上面的式子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.10.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;这是一个exp-loss的multi-stage，我们把所谓的方向当做base learner的话，等价到优化w，w是一个参数，比优化函数好太多，展开一阶Taylor可以得到递推式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.11.png&quot; height=&quot;110&quot;&gt;&lt;/p&gt;
&lt;p&gt;事实上，指数部分和前面求的“步长”有关。所谓的权重，换个说法，也就是抽样的概率。对比一下，其实这里推导出来的“步长”和权重已经得到了AdaBoost。&lt;/p&gt;
&lt;p&gt;采用不同的loss-func. 可以得到不同的Boosting算法，区别在于“步长”和权重：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.12.png&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;3-GBDT&quot;&gt;&lt;a href=&quot;#3-GBDT&quot; class=&quot;headerlink&quot; title=&quot;3.GBDT&quot;&gt;&lt;/a&gt;3.GBDT&lt;/h2&gt;&lt;p&gt;GBDT是一种Tree算法。前面没有直接求“方向”，而是采用reduction的思想。GBDT采用一定策略求这个“方向”。当然还是采用迭代的方法求解。采用平方损失。&lt;/p&gt;
&lt;p&gt;这里最难解决的还是如何求“函数方向”。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.14.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;求解方向的目标是让f(x)和y的残差越来越小。那么，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.13.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果已知“方向”的形式，如D.T.，这实际就是一个回归问题了，已经有很好的数值解法。求解出了“函数方向”，“步长”就容易多了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.15.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;这是一个一维回归问题。算法基本如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.14.16.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;最后其实就是返回了方向和步长乘积的和。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习10&quot;&gt;&lt;a href=&quot;#机器学习10&quot; class=&quot;headerlink&quot; title=&quot;机器学习10&quot;&gt;&lt;/a&gt;机器学习10&lt;/h1&gt;&lt;h2 id=&quot;1-Boosting&quot;&gt;&lt;a href=&quot;#1-Boosting&quot; class=&quot;headerli
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(9)</title>
    <link href="http://yoursite.com/2016/04/14/ML9/"/>
    <id>http://yoursite.com/2016/04/14/ML9/</id>
    <published>2016-04-14T09:46:05.000Z</published>
    <updated>2016-04-13T10:52:31.358Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习9&quot;&gt;&lt;a href=&quot;#机器学习9&quot; class=&quot;headerlink&quot; title=&quot;机器学习9&quot;&gt;&lt;/a&gt;机器学习9&lt;/h1&gt;&lt;h2 id=&quot;1-Bootstrapping&quot;&gt;&lt;a href=&quot;#1-Bootstrapping&quot; class=&quot;headerlink&quot; title=&quot;1.Bootstrapping&quot;&gt;&lt;/a&gt;1.Bootstrapping&lt;/h2&gt;&lt;p&gt;bootstrapping是统计学的一大类方法。&lt;/p&gt;
&lt;p&gt;In statistics, bootstrapping can refer to any test or metric that relies on random sampling with replacement.  This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods. Generally, it falls in the broader class of resampling methods.&lt;/p&gt;
&lt;p&gt;简单来说，bootstrap sampling给定m个样本的数据集，我们随机抽取一个样本放入采样集，再把该样本放回原始数据集，使得它仍有机会被抽到，这样经过m次随机采样，得到m个样本。&lt;/p&gt;
&lt;p&gt;由于每一次，每个样本被选取的概率都是1/m，采样m次，则某个样本始终没出现的概率为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.13.2.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;也就是说，会有36.8%的数据总是没有被选到，这样在validation set就可以利用这36.8%的数据。叫做“out-of-bag estimate”。实务上，只需要记录没有被选取的数据就可以。&lt;/p&gt;
&lt;h2 id=&quot;2-Bootstrap-Aggregation&quot;&gt;&lt;a href=&quot;#2-Bootstrap-Aggregation&quot; class=&quot;headerlink&quot; title=&quot;2.Bootstrap Aggregation&quot;&gt;&lt;/a&gt;2.Bootstrap Aggregation&lt;/h2&gt;&lt;p&gt;简称bagging，是机器学习中常用的并行aggregation方法。具体原理就是采用boostrap sampling，训练不同的base learners。最后组合到一起。这里的base learner要尽可能相互独立。&lt;/p&gt;
&lt;p&gt;例如将决策树作为base learner，将LinReg作为base learner，将ANN作为base learner都无不可。但是仍然要注意overfitting，如果全是精英，那么往往听不到下层的声音。。。由于bagging 关注于降低var，所以var较大的base learner可以与bagging结合，例如未剪枝的决策树。&lt;/p&gt;
&lt;h2 id=&quot;3-随机森林&quot;&gt;&lt;a href=&quot;#3-随机森林&quot; class=&quot;headerlink&quot; title=&quot;3.随机森林&quot;&gt;&lt;/a&gt;3.随机森林&lt;/h2&gt;&lt;p&gt;Random Forest是将D.T.与bagging结合起来的一种模型。但是RF在D.T.的训练过程中引入了随机属性选择机制，这样大大提高了base learner的多样性。RF往往比单纯的D.T.+bagging效果好。&lt;/p&gt;
&lt;p&gt;在RF中，岁D.T.的每个节点，先从该点属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这样得到若干棵D.T.，再将这个森林进行集成，就可以得到模型的输出。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习9&quot;&gt;&lt;a href=&quot;#机器学习9&quot; class=&quot;headerlink&quot; title=&quot;机器学习9&quot;&gt;&lt;/a&gt;机器学习9&lt;/h1&gt;&lt;h2 id=&quot;1-Bootstrapping&quot;&gt;&lt;a href=&quot;#1-Bootstrapping&quot; class=&quot;he
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(8)</title>
    <link href="http://yoursite.com/2016/04/13/ML8/"/>
    <id>http://yoursite.com/2016/04/13/ML8/</id>
    <published>2016-04-13T03:46:05.000Z</published>
    <updated>2016-04-13T10:52:31.358Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习8&quot;&gt;&lt;a href=&quot;#机器学习8&quot; class=&quot;headerlink&quot; title=&quot;机器学习8&quot;&gt;&lt;/a&gt;机器学习8&lt;/h1&gt;&lt;p&gt;决策树(D.T.)属于conditional voting的multi-stage模型。D.T.的base learner是只含2层的D.T.，叫做decision stump，每一层在一定条件下进行分支。&lt;/p&gt;
&lt;p&gt;同样套入统计机器学习框架，我们关注的还是erri和Regul.两个问题。（当然还有优化方法和数值计算问题）&lt;/p&gt;
&lt;h2 id=&quot;1-Regression-Tree&quot;&gt;&lt;a href=&quot;#1-Regression-Tree&quot; class=&quot;headerlink&quot; title=&quot;1.Regression Tree&quot;&gt;&lt;/a&gt;1.Regression Tree&lt;/h2&gt;&lt;p&gt;首先看erri。对于回归，最普遍的是采用二次损失。在D.T.中，将erri解释为impurity，在树分支的过程中，impurity要越来越低，而每一步的分支要尽可能降低impurity。&lt;/p&gt;
&lt;p&gt;每一步要寻找让impurity降低最明显的feature，并且要找到这个feature让impurity降低最明显的阈值。&lt;/p&gt;
&lt;p&gt;如下例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.13.3.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;在二维空间，表示的分界面如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.13.4.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，RegTree实际上在用一定数量的超平面模拟分界曲面，如果分支无限下去，就可以得到曲面。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.13.5.png&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;2-Classification-Tree&quot;&gt;&lt;a href=&quot;#2-Classification-Tree&quot; class=&quot;headerlink&quot; title=&quot;2.Classification Tree&quot;&gt;&lt;/a&gt;2.Classification Tree&lt;/h2&gt;&lt;p&gt;对于分类，我们前面采用过0/1 loss,log-loss,cross-entropy loss,exp-loss,hindge loss,etc。这里没有得分的概念，输入空间是完全离散的，但是impurity依然适用。可以采用误分类率，信息增益，Gini index等。CART采用Gini index。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.13.6.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;直观上说，Gini反映了数据集D中随机抽取两个样本，其类别标记不一致的概率，也就是impurity。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.13.7.png&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;3-pruning&quot;&gt;&lt;a href=&quot;#3-pruning&quot; class=&quot;headerlink&quot; title=&quot;3.pruning&quot;&gt;&lt;/a&gt;3.pruning&lt;/h2&gt;&lt;p&gt;不论是RegTree还是ClsTree，共有的缺点是variance较大，对外部反应过于敏感，泛化能力不足。容易overfitting。这时肯定要采用Regul.，对D.T来说，就是pruning。&lt;/p&gt;
&lt;p&gt;prepruning是在D.T.的生长过程中，对每个节点在划分之前，先于val. set上的数据对比，看正确率大小，如果在val. set上正确率提升，就划分，否则就禁止划分。postpruning是在训练结束后回溯地进行pruning。prepruning不仅能防止overfitting，还可以减少训练时间。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.13.8.png&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习8&quot;&gt;&lt;a href=&quot;#机器学习8&quot; class=&quot;headerlink&quot; title=&quot;机器学习8&quot;&gt;&lt;/a&gt;机器学习8&lt;/h1&gt;&lt;p&gt;决策树(D.T.)属于conditional voting的multi-stage模型。D.T.的base lear
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(7)</title>
    <link href="http://yoursite.com/2016/04/12/ML7/"/>
    <id>http://yoursite.com/2016/04/12/ML7/</id>
    <published>2016-04-12T09:46:05.000Z</published>
    <updated>2016-04-13T10:52:31.358Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习7&quot;&gt;&lt;a href=&quot;#机器学习7&quot; class=&quot;headerlink&quot; title=&quot;机器学习7&quot;&gt;&lt;/a&gt;机器学习7&lt;/h1&gt;&lt;h2 id=&quot;1-training-set-validation-set-test-set&quot;&gt;&lt;a href=&quot;#1-training-set-validation-set-test-set&quot; class=&quot;headerlink&quot; title=&quot;1.training set, validation set, test set&quot;&gt;&lt;/a&gt;1.training set, validation set, test set&lt;/h2&gt;&lt;p&gt;training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;training set：学习模型的参数&lt;/li&gt;
&lt;li&gt;validation set：模型选择和调参&lt;/li&gt;
&lt;li&gt;test set：最终的模型评估 &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;固定的划分数据集的方法叫做handout，这种方法的缺点是容易导致训练数据减少，一种可行的方法是cross-validation，对于k-fold CV，将数据分为k份，数据在k-1份上做训练，在剩下来的数据上做validation。这样可以在数据集上做k次训练和测试，最终按照一定方法取值（例如均值）。由于划分数据集的方法是随机的，所以可以进行p次数据集划分，叫做p次k-fold CV。&lt;/p&gt;
&lt;h2 id=&quot;2-multi-stage&quot;&gt;&lt;a href=&quot;#2-multi-stage&quot; class=&quot;headerlink&quot; title=&quot;2.multi-stage&quot;&gt;&lt;/a&gt;2.multi-stage&lt;/h2&gt;&lt;p&gt;multi-stage是将特征进行多次映射，最终映射到输出空间。广义上讲，大部分学习器都是multi-stage的，这里的multi-stage特指将base learner aggregate to good(or better) learner。这类模型的最大优点在于降低variance，提升泛化性能，但是erri却不一定降低。所以抗overfitting的性能很好。&lt;/p&gt;
&lt;p&gt;那么问题是base learner怎样获得，base learner到better learner的映射关系如何建立。&lt;/p&gt;
&lt;p&gt;事实上，base learner的要求只有一条”good enough but different”，精确性和多样性本来就是有矛盾的。但我们想达到一种平衡。但是good enough即可，如果太好，反而可能造成overfitting（全是精英，商量的结果有可能脱离实际。。。）&lt;/p&gt;
&lt;p&gt;其次，base learner到better learner的映射关系如何建立。主要有5种：selection，uniform voting，linear voting，any voting，conditional voting。selection是uniform voting的退化情形，uniform voting是linear voting的退化情形，linear voting是any voting的退化情形，conditional voting是决策树采用的方式。&lt;/p&gt;
&lt;p&gt;方式上，对样本的方法有bootstapping和boosting，对model的方法有blending。&lt;/p&gt;
&lt;h2 id=&quot;3-Blending&quot;&gt;&lt;a href=&quot;#3-Blending&quot; class=&quot;headerlink&quot; title=&quot;3.Blending&quot;&gt;&lt;/a&gt;3.Blending&lt;/h2&gt;&lt;p&gt;从model角度，实现multi-stage的方法。具体而言，至少2-stages：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;get base learners&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;blend them to a better learner&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果采用selction，那么就属于模型选择问题。如果采用uniform voting，就等同于uninformative prior。linear voting或者叫weighted voting，如果有很好的先验知识，优于uniform voting，但是multi-stage多多少少都有blackbox的性质，精确的先验确实是比较难的。any voting非常强大，但是又有overfitting之虞。&lt;/p&gt;
&lt;p&gt;如果不采用prior，而是采用data-driven的方法，叫做stacking。简单来说，在traning set上得到base learner，把它当做一个特征转换，然后在把base learner的输出当做次级的输入，在validation set上继续训练。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习7&quot;&gt;&lt;a href=&quot;#机器学习7&quot; class=&quot;headerlink&quot; title=&quot;机器学习7&quot;&gt;&lt;/a&gt;机器学习7&lt;/h1&gt;&lt;h2 id=&quot;1-training-set-validation-set-test-set&quot;&gt;&lt;a href=&quot;#1-t
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(6)</title>
    <link href="http://yoursite.com/2016/04/12/ML6/"/>
    <id>http://yoursite.com/2016/04/12/ML6/</id>
    <published>2016-04-12T01:46:05.000Z</published>
    <updated>2016-04-24T14:19:41.184Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习6&quot;&gt;&lt;a href=&quot;#机器学习6&quot; class=&quot;headerlink&quot; title=&quot;机器学习6&quot;&gt;&lt;/a&gt;机器学习6&lt;/h1&gt;&lt;h2 id=&quot;1-Bayesian视角下的kernel-method&quot;&gt;&lt;a href=&quot;#1-Bayesian视角下的kernel-method&quot; class=&quot;headerlink&quot; title=&quot;1.Bayesian视角下的kernel method&quot;&gt;&lt;/a&gt;1.Bayesian视角下的kernel method&lt;/h2&gt;&lt;p&gt;由于kernel天然具有协方差的性质，所以K=COV。我们将函数某点的值Xi当做随机变量，由于每一点都具有随机性，所以我们可以定义一个随机过程。这个随机过程的均值是容易得到的，协方差为K。根据最大熵原理，我们定义一个高斯随机过程（GP）。&lt;br&gt;即，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/0/6/9/06910726f457f8e2def752f7612a810f.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;根据l2-Regul. LM的表示定理，我们考察一个高斯分布：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/e/7/0/e704a6f532e8205441c1f319942674f6.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/a/f/b/afb63bc04d1de00487843a9971042e96.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;假定w的先验分布为高斯：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/0/2/a/02ae62fe5b79030172cf227bedff6712.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;likelihood也为高斯：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/4/c/7/4c79a4eb076bf27ccf7be856b3c7c991.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;那么f的后验为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/c/f/3/cf375eacfe4aba90897016ae03759b3a.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;可见，w的先验，同时也是l2-Regul. 变为了GP的噪声，由于表示定理的作用，kernel变为了后验的随机变量。&lt;/p&gt;
&lt;h2 id=&quot;2-Bayesian-LinReg&quot;&gt;&lt;a href=&quot;#2-Bayesian-LinReg&quot; class=&quot;headerlink&quot; title=&quot;2.Bayesian LinReg&quot;&gt;&lt;/a&gt;2.Bayesian LinReg&lt;/h2&gt;&lt;p&gt;思考OLS和Ridge Reg的概率解释，在贝叶斯语义下，计算MAP的时候，已经得到了posterior，如何估计参数呢？MAP采用点估计，也可以采用Bayesian decision theory。但是与Ridge Reg不同的是罚因子不是由人工决定的，而是数据决定的。下面讨论Bayesian posterior predictive(简称predictive)： &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.24.5.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;此时y的预测和并不需要估计w，而是取决于超参数a,b。对a,b采用unimformative prior,就可以得到结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.24.6.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;Baysian模型的一大好处是：自动抗overfitting，因为计算predictive的时候已经自动对参数进行了average。但是，明显可以看到，缺点是太难推导，运气好的是这里起码可以积出来一个close form解，很多情况下，根本积不出来，这个时候就有所谓的变分推断，MCMC等高级技术。&lt;/p&gt;
&lt;h2 id=&quot;3-Bayesian-LogReg&quot;&gt;&lt;a href=&quot;#3-Bayesian-LogReg&quot; class=&quot;headerlink&quot; title=&quot;3.Bayesian LogReg&quot;&gt;&lt;/a&gt;3.Bayesian LogReg&lt;/h2&gt;&lt;p&gt;y~Bern(p)，我们找不到一个优良的先验分布，但又不想使用uninformative prior。这个时候使用appropriation来做。由于Gaussian有良好的congjugate prior，Bern和Gaussian都属于指数分布族，我们考虑使用Gaussian去近似Bern分布。（Laplace appropriation）&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.1.3.gif&quot;&gt;&lt;br&gt;具体不再深入。（可见PRML和MLPP）&lt;/p&gt;
&lt;h2 id=&quot;4-Bayesian-Occam’s-Razor-BIC-VC-dim&quot;&gt;&lt;a href=&quot;#4-Bayesian-Occam’s-Razor-BIC-VC-dim&quot; class=&quot;headerlink&quot; title=&quot;4.Bayesian Occam’s Razor, BIC, VC dim&quot;&gt;&lt;/a&gt;4.Bayesian Occam’s Razor, BIC, VC dim&lt;/h2&gt;&lt;p&gt;所谓的贝叶斯奥卡姆剃刀（Bayesian Occam’s Razor）,因为这个剃刀工作在贝叶斯公式的似然（P(D | h) ）上，而不是模型本身（ P(h) ）的先验概率上。关于贝叶斯奥卡姆剃刀我们再来看一个前面说到的曲线拟合的例子：如果平面上有 N 个点，近似构成一条直线，但绝不精确地位于一条直线上。这时我们既可以用直线来拟合（模型1），也可以用二阶多项式（模型2）拟合，也可以用三阶多项式（模型3），.. ，特别地，用 N-1 阶多项式便能够保证肯定能完美通过 N 个数据点。那么，这些可能的模型之中到底哪个是最靠谱的呢？前面提到，一个衡量的依据是奥卡姆剃刀：越是高阶的多项式越是繁复和不常见。然而，我们其实并不需要依赖于这个先验的奥卡姆剃刀，因为有人可能会争辩说：你怎么就能说越高阶的多项式越不常见呢？我偏偏觉得所有阶多项式都是等可能的。好吧，既然如此那我们不妨就扔掉 P(h) 项，看看 P(D | h) 能告诉我们什么。我们注意到越是高阶的多项式，它的轨迹弯曲程度越是大，到了八九阶简直就是直上直下，于是我们不仅要问：一个比如说八阶多项式在平面上随机生成的一堆 N 个点偏偏恰好近似构成一条直线的概率（即 P(D | h) ）有多大？太小太小了。反之，如果背后的模型是一条直线，那么根据该模型生成一堆近似构成直线的点的概率就大得多了。这就是贝叶斯奥卡姆剃刀。(  摘自&lt;a href=&quot;http://goo.gl/CkCyUs&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://goo.gl/CkCyUs&lt;/a&gt; )&lt;/p&gt;
&lt;p&gt;而贝叶斯方法通常使用的是不同model下的posterior：p(m|D,w)，我们的要求是找到一个model使得这个posterior最大。另一种方法是看marginal likelihood（p(D|m))，也就是积分后的likelihood，这等效于对参数averaging的结果，也就是将各种各种likelihood进行了voting，这样的likelihood自动避免了overfitting。&lt;/p&gt;
&lt;p&gt;使用Laplace approx.去重写p(D|m)，得到了log(p(D|m))的asymptotic结果，就是BIC：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/c/d/c/cdc9466caa55f66578c9660880b2f4db.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;前面一部分可以认为是erri，后面一部分是负的泛化能力。BIC越小，模型的erro越小。著名的AIC也说明了这个道理：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/7/5/a/75a00ba4d67592a77bb87db1c723ddfe.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;VC dim也说明了这个问题：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.9.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;平衡模型两类能力是机器学习的重要话题。最难平衡的情形就是overfitting，怎么抗overfitting就体现了model designer关于模型的先验与智慧了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.13.1.png&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习6&quot;&gt;&lt;a href=&quot;#机器学习6&quot; class=&quot;headerlink&quot; title=&quot;机器学习6&quot;&gt;&lt;/a&gt;机器学习6&lt;/h1&gt;&lt;h2 id=&quot;1-Bayesian视角下的kernel-method&quot;&gt;&lt;a href=&quot;#1-Bayesian视角下的
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(5)</title>
    <link href="http://yoursite.com/2016/04/11/ML5/"/>
    <id>http://yoursite.com/2016/04/11/ML5/</id>
    <published>2016-04-11T09:46:05.000Z</published>
    <updated>2016-04-24T14:17:25.100Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习5&quot;&gt;&lt;a href=&quot;#机器学习5&quot; class=&quot;headerlink&quot; title=&quot;机器学习5&quot;&gt;&lt;/a&gt;机器学习5&lt;/h1&gt;&lt;h2 id=&quot;1-Transform-OR-Basis&quot;&gt;&lt;a href=&quot;#1-Transform-OR-Basis&quot; class=&quot;headerlink&quot; title=&quot;1.Transform OR Basis&quot;&gt;&lt;/a&gt;1.Transform OR Basis&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.24.3.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;对x在一个basis下施以变换，使得x首先完成一个特征转换。LM是指w的线性，而不是特征特征一定是线性。&lt;/p&gt;
&lt;h2 id=&quot;2-kernel-trick&quot;&gt;&lt;a href=&quot;#2-kernel-trick&quot; class=&quot;headerlink&quot; title=&quot;2.kernel trick&quot;&gt;&lt;/a&gt;2.kernel trick&lt;/h2&gt;&lt;p&gt;我采用MLPP的说法：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Rather than defining our feature vector in terms of kernels, φ(x) = [κ(x,x 1),…,κ(x,xn)], we can instead work with the original feature vectors x, but modify the algorithm so that it replaces all inner products of the form  &amp;lt;x,x’&amp;gt; with a call to the kernel function, κ(x,x’).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;凡是在内积空间的变换总是可以有kernel与之对应。而且如前所述，kernel的一大特点是可以embedding infinite features。Representer Theorem只是kernel trick一个子集。&lt;/p&gt;
&lt;h2 id=&quot;3-kernel-kNN-and-kernel-k-means&quot;&gt;&lt;a href=&quot;#3-kernel-kNN-and-kernel-k-means&quot; class=&quot;headerlink&quot; title=&quot;3.kernel kNN and kernel k-means&quot;&gt;&lt;/a&gt;3.kernel kNN and kernel k-means&lt;/h2&gt;&lt;p&gt;kNN天然可以kernelized，因为采用l2-norm的kNN天然具备内积这一个优化条件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.24.4.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;l2-norm的k-means也是这样。两点之间的距离可以化为kernel。&lt;/p&gt;
&lt;h2 id=&quot;4-kernel-machine&quot;&gt;&lt;a href=&quot;#4-kernel-machine&quot; class=&quot;headerlink&quot; title=&quot;4.kernel machine&quot;&gt;&lt;/a&gt;4.kernel machine&lt;/h2&gt;&lt;p&gt;GLM中feature表示为：&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.1.gif&quot;&gt;叫做kernel machine。&lt;/p&gt;
&lt;p&gt;如果为RBF kernel，则得到一个RBF NNet。误差采用二次误差，激活函数采用RBF函数。&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.2.png&quot;&gt;&lt;br&gt;Architecture of a radial basis function network. An input vector x is used as input to all radial basis functions, each with different parameters. The output of the network is a linear combination of the outputs from radial basis functions.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.3.png&quot;&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.4.png&quot;&gt;&lt;/center&gt;

&lt;p&gt;注意，这和RBF-kernelized SVM很相似，除了采用的loss func.不同，实际上，ANN可以包含一切supervised model，ANN每一层都在做feature transformation~T(x)，BP算法在argmin erri。LM只是层数较少的（2~3层）ANN而已。&lt;/p&gt;
&lt;p&gt;再注意到，如果采用uniform vote，那么这个kernel machine等同于欧氏距离的kNN算法。因为内积空间的内积度量实际也在距离度量，RBF kernel实际在度量特征的欧氏距离。&lt;/p&gt;
&lt;p&gt;如何确定ci？可以使用clustering，例如k-means。&lt;/p&gt;
&lt;p&gt;如果我不想使用unsupervised算法呢？最直接的方法是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.5.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;但是这样会导致模型的泛化能力很成问题，计算复杂度也有点高，我们希望w尽可能稀疏一点，这样就引入了sparse vector machine，SVM就是一种sparse vector machine。&lt;/p&gt;
&lt;h2 id=&quot;5-kernel-PCA&quot;&gt;&lt;a href=&quot;#5-kernel-PCA&quot; class=&quot;headerlink&quot; title=&quot;5.kernel PCA&quot;&gt;&lt;/a&gt;5.kernel PCA&lt;/h2&gt;&lt;p&gt;PCA方法实际是在操作Gram矩阵，而Gram矩阵与kernel有天然的联系。所以kernel PCA是最天然不过的了。对于非线性相关的数据，通过kernel将其转化为线性相关问题，这样PCA就可以奏效。&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.6.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;则kernel为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.7.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个kernel可以组成kernel矩阵，也是cov矩阵，再做一点变换：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.12.8.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;对变换后的kernel矩阵做标准的PCA操作就可以得到kernel PCA&lt;/p&gt;
&lt;h2 id=&quot;6-非参统计的核方法（待）&quot;&gt;&lt;a href=&quot;#6-非参统计的核方法（待）&quot; class=&quot;headerlink&quot; title=&quot;6.非参统计的核方法（待）&quot;&gt;&lt;/a&gt;6.非参统计的核方法（待）&lt;/h2&gt;</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习5&quot;&gt;&lt;a href=&quot;#机器学习5&quot; class=&quot;headerlink&quot; title=&quot;机器学习5&quot;&gt;&lt;/a&gt;机器学习5&lt;/h1&gt;&lt;h2 id=&quot;1-Transform-OR-Basis&quot;&gt;&lt;a href=&quot;#1-Transform-OR-Basis&quot;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>信息论对社会信息化的作用（转）</title>
    <link href="http://yoursite.com/2016/04/10/info-theory/"/>
    <id>http://yoursite.com/2016/04/10/info-theory/</id>
    <published>2016-04-10T14:46:05.000Z</published>
    <updated>2016-04-13T11:06:01.190Z</updated>
    
    <content type="html">&lt;h1 id=&quot;信息论对社会信息化的作用——纪念Shannon百年诞辰&quot;&gt;&lt;a href=&quot;#信息论对社会信息化的作用——纪念Shannon百年诞辰&quot; class=&quot;headerlink&quot; title=&quot;信息论对社会信息化的作用——纪念Shannon百年诞辰&quot;&gt;&lt;/a&gt;信息论对社会信息化的作用——纪念Shannon百年诞辰&lt;/h1&gt;&lt;p&gt;此文为&lt;strong&gt;王育民&lt;/strong&gt;先生所写，虽然着重于网络安全的讨论，但仍不失为一篇很有水平的科普文章。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://news.xidian.edu.cn/view-52201.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/shannon.jpg&quot; width=&quot;300&quot; height=&quot;365&quot;&gt;&lt;/p&gt;
&lt;p&gt;神人香农，21岁获得MIT硕士学位，他的硕士毕业论文奠定了数字逻辑电路设计的理论基础，11年后发表的《通信的数学理论》建立了信息论和编码理论，1年后的《保密系统的通信理论》建立了现代密码学和信息安全理论，没有这三项成果可能就没有所谓的数字时代吧。不仅如此，作为数学家的香农搞出的理论奠定了现代生活的理论基础，他也是一个工程师：能做硬件，会写程序。&lt;/p&gt;
&lt;p&gt;一个人，用自己一辈子推进了整个时代的进步，他所做的一切可能只是追寻他心中那份真正的快乐而已。纪念他最好的方式也许不是纪念，而是问问自己真正的快乐是什么。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://pan.baidu.com/s/1qYGcSnM&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;附：：Shannon - A Mathematical Theory of Communication原文&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;信息论对社会信息化的作用——纪念Shannon百年诞辰&quot;&gt;&lt;a href=&quot;#信息论对社会信息化的作用——纪念Shannon百年诞辰&quot; class=&quot;headerlink&quot; title=&quot;信息论对社会信息化的作用——纪念Shannon百年诞辰&quot;&gt;&lt;/a&gt;信息论对社
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(4)</title>
    <link href="http://yoursite.com/2016/04/09/ML4/"/>
    <id>http://yoursite.com/2016/04/09/ML4/</id>
    <published>2016-04-09T09:46:05.000Z</published>
    <updated>2016-04-10T09:59:22.870Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习1——线性模型-4&quot;&gt;&lt;a href=&quot;#机器学习1——线性模型-4&quot; class=&quot;headerlink&quot; title=&quot;机器学习1——线性模型(4)&quot;&gt;&lt;/a&gt;机器学习1——线性模型(4)&lt;/h1&gt;&lt;h2 id=&quot;1-kernel-Ridge-Regression&quot;&gt;&lt;a href=&quot;#1-kernel-Ridge-Regression&quot; class=&quot;headerlink&quot; title=&quot;1.kernel Ridge Regression&quot;&gt;&lt;/a&gt;1.kernel Ridge Regression&lt;/h2&gt;&lt;p&gt;将表示定理用于Ridge Regression，可以将线性Ridge Regression推广到非线性。再叙述一次表示定理：&lt;/p&gt;
&lt;p&gt;简单来说，一个优化问题表示为：argmin err(out)=l[(x1,y1,f(x1),…,(xn,yn,f(xn)]+g(||f||) &lt;/p&gt;
&lt;p&gt;此时，l(.)非负，g(.)为单调增函数，那么存在满足Mercer定理的核函数，使得解总可以写作：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.6.5.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于l2-norm regularization LM：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.7.1.gif&quot;&gt;&lt;br&gt;我们将看到，这个定理的强大作用。它使LM变成了非线性模型，而不需要对LM的框架更改许多。&lt;/p&gt;
&lt;p&gt;Ridge Reg可以表示为:argmin 平方损失+l2-norm regularization。完全符合表示定理。则：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.7.2.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;使用矩阵表示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.7.3.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;解得&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.7.4.gif&quot;&gt;&lt;br&gt;但是这个矩阵比较dense，数值解会浪费时间，且解不稳定。所以实务中用的不多。&lt;/p&gt;
&lt;h2 id=&quot;2-kernel-l2-norm-regularized-LogReg&quot;&gt;&lt;a href=&quot;#2-kernel-l2-norm-regularized-LogReg&quot; class=&quot;headerlink&quot; title=&quot;2.kernel l2-norm regularized LogReg&quot;&gt;&lt;/a&gt;2.kernel l2-norm regularized LogReg&lt;/h2&gt;&lt;p&gt;将表示定理用于l2-norm regularized LogReg，可以将线性Ridge Regression推广到非线性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.7.5.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个问题不像SVM具有稀疏性，实务中用的也不多。&lt;/p&gt;
&lt;h2 id=&quot;3-Probabilistic-SVM&quot;&gt;&lt;a href=&quot;#3-Probabilistic-SVM&quot; class=&quot;headerlink&quot; title=&quot;3.Probabilistic SVM&quot;&gt;&lt;/a&gt;3.Probabilistic SVM&lt;/h2&gt;&lt;p&gt;继续研究LogReg和SVM。&lt;/p&gt;
&lt;p&gt;soft-margin SVM使用hinge loss，LogReg使用log loss。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.7.6.jpg&quot; width=&quot;500&quot; height=&quot;200&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到log-loss和hinge-loss很相近，实际上SVM约等于l2-norm regularized LogReg。通常情况下，他们的性能也相当。LogReg主要优势在于可以直接解释为概率。SVM的主要优势在于SVM的解具有稀疏性，因而需要的样本也更少，开销小。&lt;/p&gt;
&lt;p&gt;我们可以将SVM和LogReg结合起来。先使用SVM得到一个线性模型。然后将转换后的数据带入LogReg，SVM中可以使用kernel，这个模型同样可以实现非线性分类。这就是所谓的2-stage model。叫做probabilistic SVM。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.7.7.gif&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;4-SVR&quot;&gt;&lt;a href=&quot;#4-SVR&quot; class=&quot;headerlink&quot; title=&quot;4.SVR&quot;&gt;&lt;/a&gt;4.SVR&lt;/h2&gt;&lt;p&gt;将SVM的思想推广到回归就得到了SVR。让回归曲线也尽可能“胖”一点。仿照soft-margin SVM：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.9.1.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;按照SVM的思路，可以导出SVR，同样可以kernel化。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习1——线性模型-4&quot;&gt;&lt;a href=&quot;#机器学习1——线性模型-4&quot; class=&quot;headerlink&quot; title=&quot;机器学习1——线性模型(4)&quot;&gt;&lt;/a&gt;机器学习1——线性模型(4)&lt;/h1&gt;&lt;h2 id=&quot;1-kernel-Ridge-Regr
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(3)</title>
    <link href="http://yoursite.com/2016/04/09/ML3/"/>
    <id>http://yoursite.com/2016/04/09/ML3/</id>
    <published>2016-04-09T09:45:15.000Z</published>
    <updated>2016-04-24T14:16:16.004Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习1——线性模型-3&quot;&gt;&lt;a href=&quot;#机器学习1——线性模型-3&quot; class=&quot;headerlink&quot; title=&quot;机器学习1——线性模型(3)&quot;&gt;&lt;/a&gt;机器学习1——线性模型(3)&lt;/h1&gt;&lt;h2 id=&quot;1-hard-margin-SVM&quot;&gt;&lt;a href=&quot;#1-hard-margin-SVM&quot; class=&quot;headerlink&quot; title=&quot;1.hard-margin SVM&quot;&gt;&lt;/a&gt;1.hard-margin SVM&lt;/h2&gt;&lt;p&gt;支持向量模型是第二大类线性模型，它着眼于直接增强模型的泛化能力。即让分界面尽可能的“胖”。SVM用于分类。&lt;/p&gt;
&lt;p&gt;如果分类器能正确分类：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.1.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;一个点在n维空间到分类超平面的距离：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.2.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;取分子为边界值：（即hard-margin）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.3.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;此时，我们得到一个有约束的优化问题：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.4.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个问题不好优化，把它变成一个好优化的问题（等价变换）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.5.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;这是一个二次优化问题。（凸问题是最愿意见到的一个问题）对比具有hard-margin和没有margin的情形：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.6.png&quot;&gt;   &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.7.png&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;2-soft-margin-SVM&quot;&gt;&lt;a href=&quot;#2-soft-margin-SVM&quot; class=&quot;headerlink&quot; title=&quot;2.soft-margin SVM&quot;&gt;&lt;/a&gt;2.soft-margin SVM&lt;/h2&gt;&lt;p&gt;在前面的讨论中，我们一直假定训练样本是线性可分的，然而，现实中很多数据不是线性可分的，这个时候要进一步提升模型的泛化能力。使它也能容忍一部分线性不可分的training data。&lt;/p&gt;
&lt;p&gt;采用增加正则化项的方法：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.8.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;后面那部分就是正则化项（罚函数），也就是优化问题会同时考虑margin最大和误分类点尽可能少。但0/1损失数学性质不好，我们改为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.9.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;其中max(0,1-z)叫做hinge损失函数。如果换一个看法：err(out)=hinge(s)+l2-norm Regularization。又回到了经典的LM那里。&lt;/p&gt;
&lt;p&gt;换第三个看法：引入松弛变量，将式子再改写一下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.10.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意到和hard-margin SVM 相比，soft-margin SVM多了松弛变量，正是一个松弛变量让margin可以自动调整。&lt;/p&gt;
&lt;h2 id=&quot;3-SVM的Dual问题&quot;&gt;&lt;a href=&quot;#3-SVM的Dual问题&quot; class=&quot;headerlink&quot; title=&quot;3.SVM的Dual问题&quot;&gt;&lt;/a&gt;3.SVM的Dual问题&lt;/h2&gt;&lt;p&gt;基于优化的primal-dual理论，我们可以得到hard-margin SVM和soft-margin SVM的dual问题。&lt;/p&gt;
&lt;p&gt;dual hard-margin SVM:&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.11.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;dual soft-margin SVM:&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.5.12.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;由对偶松弛条件，dual问题有较为稀疏的解，这是我们愿意看到的。&lt;/p&gt;
&lt;h2 id=&quot;4-Representer-Theorem&quot;&gt;&lt;a href=&quot;#4-Representer-Theorem&quot; class=&quot;headerlink&quot; title=&quot;4.Representer Theorem&quot;&gt;&lt;/a&gt;4.Representer Theorem&lt;/h2&gt;&lt;p&gt;kernel在数学上是一个很宽泛的概念，这里的kernel特指能够隐形的进行内积运算的函数：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.6.1.gif&quot;&gt;&lt;br&gt;试想，如果没有kernel，进行上述运算，运算复杂度为平方量级，如果引入kernel，会变成线性量级。其次，kernel可以很好的表示无限维的feature，以similarity为度量，将无限维的feature隐式的包含在kernel里。（embedding infinite features in kernel）&lt;/p&gt;
&lt;p&gt;观察dual hard-margin SVM和dual soft-margin SVM，里面含有内积运算。但是他们仍然只能进行线性分类，如果我们有一种映射，将低维不可分映射到足够高维，可能就会成为高维的线性可分问题。&lt;/p&gt;
&lt;p&gt;此时dual soft-margin SVM:&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.6.2.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;使用kernel:&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.6.3.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;这样线性分类的SVM自然地扩展到了非线性。&lt;/p&gt;
&lt;p&gt;再深入讨论。只有核矩阵是半正定（半正定Gram矩阵）的kernel才是可用的kernel(Mercer定理)。事实上，对于一个半正定的核矩阵，总能找到一个与之对应的映射。任何一个kernel都隐式定义了一个再生希尔伯特核空间(RKHS)。（内积可以再生成原始函数的Hilbert Space）&lt;/p&gt;
&lt;p&gt;数学推导得到了重要的&lt;strong&gt;表示定理&lt;/strong&gt;：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.6.4.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;简单来说，一个优化问题表示为：argmin err(out)=l[(x1,y1,f(x1),…,(xn,yn,f(xn)]+g(||f||) &lt;/p&gt;
&lt;p&gt;此时，l(.)非负，g(.)为单调增函数，那么存在满足Mercer定理的核函数，使得解总可以写作：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.6.5.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于l2-norm Regul. LM：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.7.1.gif&quot;&gt;&lt;br&gt;我们将看到，这个定理的强大作用。它使LM变成了非线性模型，而不需要对LM的框架更改许多。&lt;/p&gt;
&lt;p&gt;将SVM的dual很容易推广到非线性情形。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习1——线性模型-3&quot;&gt;&lt;a href=&quot;#机器学习1——线性模型-3&quot; class=&quot;headerlink&quot; title=&quot;机器学习1——线性模型(3)&quot;&gt;&lt;/a&gt;机器学习1——线性模型(3)&lt;/h1&gt;&lt;h2 id=&quot;1-hard-margin-SVM&quot;&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(2)</title>
    <link href="http://yoursite.com/2016/04/02/ML2/"/>
    <id>http://yoursite.com/2016/04/02/ML2/</id>
    <published>2016-04-02T15:04:05.000Z</published>
    <updated>2016-04-24T14:15:55.796Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习1——线性模型-2&quot;&gt;&lt;a href=&quot;#机器学习1——线性模型-2&quot; class=&quot;headerlink&quot; title=&quot;机器学习1——线性模型(2)&quot;&gt;&lt;/a&gt;机器学习1——线性模型(2)&lt;/h1&gt;&lt;h2 id=&quot;1-简单的线性分类模型&quot;&gt;&lt;a href=&quot;#1-简单的线性分类模型&quot; class=&quot;headerlink&quot; title=&quot;1.简单的线性分类模型&quot;&gt;&lt;/a&gt;1.简单的线性分类模型&lt;/h2&gt;&lt;p&gt;前面介绍的线性模型(LM)适应于回归。一般的线性模型可以用于分类吗？可以有以下朴素模型：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.31.1.gif&quot;&gt;&lt;br&gt;但是这个优化问题不可导，类似于组合优化，是一个NP-hard问题。&lt;/p&gt;
&lt;p&gt;放宽一下，不要求那么精确，我们只要看y(w’x)是否同号即可：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.31.2.gif&quot;&gt;&lt;br&gt;这被称为：感知机模型(perceptron)，是最简单的一个线性分类模型，也是最简单的神经网络模型(ANN)。这个问题容易优化，使用SGD（随机梯度下降法）很容易求解。但是这个模型能力非常有限，具体将在ANN部分说明。&lt;/p&gt;
&lt;h2 id=&quot;2-广义线性模型-GLM&quot;&gt;&lt;a href=&quot;#2-广义线性模型-GLM&quot; class=&quot;headerlink&quot; title=&quot;2.广义线性模型(GLM)&quot;&gt;&lt;/a&gt;2.广义线性模型(GLM)&lt;/h2&gt;&lt;p&gt;GLM是LM的推广，在统计学上有很严密的理论支撑。机器学习领域最明显的应用是：logistic回归。&lt;br&gt;这里通过3个角度简单说明LogReg。&lt;/p&gt;
&lt;p&gt;所谓GLM，是指它扩展了OLS的误差正态性假设，假设y服从指数分布族的一个分布（正态分布是指数分布族的一支）。如果y~Bern(p)(y服从伯努利分布），那么：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.31.3.gif&quot;&gt;&lt;br&gt;当p&amp;lt;=0.5，则y=-1;当p&amp;gt;0.5，则y=+1.&lt;br&gt;这个模型具有很强的扩展性，如果y~Cat(p1,p2,…)时，可以得到用于多分类的LogReg。（这里的具体推导不书写）&lt;/p&gt;
&lt;p&gt;第二个角度更容易理解。我们定义归一化sigmoid函数(softmax)：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.31.4.gif&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.31.5.png&quot; width=&quot;500&quot; height=&quot;200&quot;&gt;&lt;br&gt;sigmoid(w’x)相当于将值域压缩到[0,1]。&lt;/p&gt;
&lt;p&gt;并且，sigmoid函数二阶可导，g’(z)=g(z)(1-g(z))，这对优化而言是好事。对LogReg的优化采用MLE+GD/SGD/Newton/quasi-Newton等数值优化方法皆可。使用GD或者Newton法都可以迭代求解。&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.1.1.gif&quot;&gt;&lt;br&gt;第三个角度仍然从形式化的LM出发。&lt;/p&gt;
&lt;p&gt;从L(w)可以得出：err(in)=log(1+exp(s))-s&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.1.4.gif&quot;&gt;&lt;br&gt;且&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.1.5.gif&quot;&gt;&lt;br&gt;可以认为log(1+exp(s))-s=log(1+exp(-s))，而log(1+exp(-s))被称为log-loss。还有一种Loss叫做cross-entropy-loss，在LogReg中，log-loss=cross-entopy-loss。所以LogReg的err(in)=log-loss(s)=cross-entropy-loss(s)&lt;/p&gt;
&lt;p&gt;如果y~N(0,1)，我们将得到probit模型，这是一个和LogReg很相似的模型，同样具有归一化作用。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习1——线性模型-2&quot;&gt;&lt;a href=&quot;#机器学习1——线性模型-2&quot; class=&quot;headerlink&quot; title=&quot;机器学习1——线性模型(2)&quot;&gt;&lt;/a&gt;机器学习1——线性模型(2)&lt;/h1&gt;&lt;h2 id=&quot;1-简单的线性分类模型&quot;&gt;&lt;a hre
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>机器学习(1)</title>
    <link href="http://yoursite.com/2016/04/02/ML1/"/>
    <id>http://yoursite.com/2016/04/02/ML1/</id>
    <published>2016-04-02T13:04:42.000Z</published>
    <updated>2016-04-24T14:15:12.912Z</updated>
    
    <content type="html">&lt;h2 id=&quot;1-OLS：一般最小二乘回归&quot;&gt;&lt;a href=&quot;#1-OLS：一般最小二乘回归&quot; class=&quot;headerlink&quot; title=&quot;1.OLS：一般最小二乘回归&quot;&gt;&lt;/a&gt;1.OLS：一般最小二乘回归&lt;/h2&gt;&lt;p&gt;这是最普通也是最原始的回归模型。在20世纪就由Gauss等数学家提出。OLS的最优特点是有闭式解，甚至不需要太多的优化手段。OLS顾名思义，采用平方损失函数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.1.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;那么最优化问题为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.2.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;得到：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.3.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.4.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;由于有close form的解（不讨论广义逆等情况），所以求解起来非常容易。请注意w*，之后的很多变形和它都有关系。&lt;/p&gt;
&lt;h2 id=&quot;2-Ridge-Regression&quot;&gt;&lt;a href=&quot;#2-Ridge-Regression&quot; class=&quot;headerlink&quot; title=&quot;2.Ridge Regression&quot;&gt;&lt;/a&gt;2.Ridge Regression&lt;/h2&gt;&lt;p&gt;对于预测的w*，有如下定理：&lt;br&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.5.gif&quot;&gt;，这是bias-varience分解的另一种表达。&lt;/p&gt;
&lt;p&gt;由于w是无偏估计（Gauss-Markov），所以：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.6.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;当X’X的特征值非常小时，会出现MSE非常大的情况。所以我们期望对w*的表达式做一改造，使之避免这种情况。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.7.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;显然，X’X的特征值将同时增大。这也是防止X’X变为奇异矩阵的方法。这会减小varience。&lt;/p&gt;
&lt;p&gt;从机器学习的角度来说，这相当于Regul.，惩罚过大的协方差。使用l2-norm Regul.(Tikhonov Regul.)防止overfitting。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.8.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ridge Reg的实现和OLS很相似，这里不再赘述。只有一个超参数需要人为调整，可以采用Grid Search或者使用先验知识等方法进行设定。&lt;/p&gt;
&lt;h2 id=&quot;3-Lasso&quot;&gt;&lt;a href=&quot;#3-Lasso&quot; class=&quot;headerlink&quot; title=&quot;3.Lasso&quot;&gt;&lt;/a&gt;3.Lasso&lt;/h2&gt;&lt;p&gt;我们还可以发现，Ridge Reg解决的实际上是数据的特征&amp;gt;数据量(n&amp;gt;m)的问题，由于r(X’X)&amp;lt;=r(X)&amp;lt;=m&amp;lt;n，而X’X是n*n的矩阵。所以减少数据的维数就可以解决。&lt;/p&gt;
&lt;p&gt;Lasso添加l1-norm Regul.罚项，它是一种更趋向于选择稀疏解的线性回归。（具体可以看统计学教材）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/3.23.9.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;罚函数为P(w)，我们假设P(w)为向量lp范。p&amp;gt;1，此时P(w)为光滑凸函数；p=1，为不光滑凸函数；0&amp;lt;p&amp;lt;1为非凸函数.&lt;/p&gt;
&lt;p&gt;我们倾向于解决p&amp;gt;1的可微凸优化问题。当p=1时，就得到Lasso。p=2为Ridge Regression。Lasso无法给出一个闭式解。需要采用优化方法。由于Lasso的稀疏性，广泛运用在sparse learning中&lt;/p&gt;
&lt;h2 id=&quot;4-概率视角&quot;&gt;&lt;a href=&quot;#4-概率视角&quot; class=&quot;headerlink&quot; title=&quot;4.概率视角&quot;&gt;&lt;/a&gt;4.概率视角&lt;/h2&gt;&lt;p&gt;以上的理论推导并未用到任何概率知识，仅仅采用最小二乘法，解了一个线性方程组而已。以下采用概率统计的视角的得到相同的结果。&lt;/p&gt;
&lt;p&gt;显然，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.24.1.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看出，OLS实际是在Gaussian分布下的MLE。&lt;/p&gt;
&lt;p&gt;我们再进行一些更复杂的推导，可以得出另一个结论。选用共轭先验：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xs6jl.com1.z0.glb.clouddn.com/4.24.2.gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ridge Reg实际是先验为Gaussian的MAP估计。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-OLS：一般最小二乘回归&quot;&gt;&lt;a href=&quot;#1-OLS：一般最小二乘回归&quot; class=&quot;headerlink&quot; title=&quot;1.OLS：一般最小二乘回归&quot;&gt;&lt;/a&gt;1.OLS：一般最小二乘回归&lt;/h2&gt;&lt;p&gt;这是最普通也是最原始的回归模型。在20世纪就
    
    </summary>
    
    
  </entry>
  
</feed>
