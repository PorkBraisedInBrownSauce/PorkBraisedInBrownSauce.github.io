<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 闲谈机器学习(13) · ClT's Blog</title><meta name="description" content="闲谈机器学习(13) - ClT"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/foowaa" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about/index.html" target="_self" class="nav-list-link">ABOUT</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">闲谈机器学习(13)</h1><div class="post-time">May 4, 2016</div><div class="post-content"><p>Bayesian Network（也叫做Belief Network）是概率图模型的重要一种，它借助DAG刻画属性间的依赖关系。因为此处确实图很多，我主要采用文字描述。以下是一个简单的BN：</p>
<p><img src="http://upload.wikimedia.org/wikipedia/commons/f/fd/SimpleBayesNetNodes.svg"></p>
<p>“事物之间的联系太过于复杂，加上一些看起来不是很过分的条件，m进行modeling。”</p>
<p>BN的假设仍然是条件独立性假设：在父节点确定的条件下，后代之间相互独立。这样联合概率分布就很容易写了：</p>
<p><img src="http://7xs6jl.com1.z0.glb.clouddn.com/5.4.1.gif"></p>
<p>BN中2变量只有1种拓扑关系，3变量主要有3种基本拓扑关系：common parent, V-structure, sequential structure。</p>
<p>这3种图中，common parent属于基本的子代互相独立，given parent；V-structure则是parent互相独立；sequential structure是爷爷与孙子相互独立，given parent。</p>
<p>对于复杂一点的DAG如何搞清楚条件独立性是一个问题，研究通常喜欢分而治之，我们想用已有知识去解决复杂问题，就引入了d-separation的概念。通过d-seperation将DAG-&gt;moral graph就可以清楚地看出所有属性之间的条件独立性。</p>
<blockquote>
<p>This definition can be made more general by defining the “d”-separation of two nodes, where d stands for directional. Let P be a trail (that is, a collection of edges which is like a path, but each of whose edges may have any direction) from node u to v. Then P is said to be d-separated by a set of nodes Z if and only if (at least) one of the following holds:</p>
<p>P contains a chain, u ← m ← v, such that the middle node m is in Z,</p>
<p>P contains a fork, u ← m → v, such that the middle node m is in Z, or</p>
<p>P contains an inverted fork (or collider), u → m ← v, such that the middle node m is not in Z and no descendant of m is in Z.</p>
<p>Thus u and v are said to be d-separated by Z if all trails between them are d-separated. If u and v are not d-separated, they are called d-connected.</p>
</blockquote>
<p>随机变量（随即向量）之间的相依关系很容易用图表示，对于理解概率模型非常有帮助：</p>
<p><img src="http://7xs6jl.com1.z0.glb.clouddn.com/LinRegPM.png"></p>
<p><img src="http://7xs6jl.com1.z0.glb.clouddn.com/BLinRegPM.png"></p>
<p>由于BN的强大表示型，必然导致学习难度高，不仅要学习概率值，还要学习结构。就如同ANN一样，一般会结合不同问题设计不同结构，学习数值。一类简单的BN是隐马尔科夫模型（HMM）。</p>
</div></article></div></section><footer><div class="paginator"><a href="/2016/05/05/ML14/" class="prev">上一篇</a><a href="/2016/05/04/ML12/" class="next">下一篇</a></div><div data-thread-key="2016/05/04/ML13/" data-title="闲谈机器学习(13)" data-url="http://yoursite.com/2016/05/04/ML13/" data-author-key="1" class="ds-thread"></div><script>var duoshuoQuery = {short_name:"seansun"};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
})();

</script><div class="copyright"><p>© 2016 <a href="http://yoursite.com">ClT</a>.This simple Blog is created by Hexo.</p></div></footer><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>