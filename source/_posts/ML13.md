---
title: 闲谈机器学习(13)
date: 2016-05-04 14:46:05
tags:
---
Bayesian Network（也叫做Belief Network）是概率图模型的重要一种，它借助DAG刻画属性间的依赖关系。因为此处确实图很多，我主要采用文字描述。以下是一个简单的BN：

<img src="http://upload.wikimedia.org/wikipedia/commons/f/fd/SimpleBayesNetNodes.svg">

“事物之间的联系太过于复杂，加上一些看起来不是很过分的条件，m进行modeling。”

BN的假设仍然是条件独立性假设：在父节点确定的条件下，后代之间相互独立。这样联合概率分布就很容易写了：

<img src="http://7xs6jl.com1.z0.glb.clouddn.com/5.4.1.gif">

BN中2变量只有1种拓扑关系，3变量主要有3种基本拓扑关系：common parent, V-structure, sequential structure。

这3种图中，common parent属于基本的子代互相独立，given parent；V-structure则是parent互相独立；sequential structure是爷爷与孙子相互独立，given parent。

对于复杂一点的DAG如何搞清楚条件独立性是一个问题，研究通常喜欢分而治之，我们想用已有知识去解决复杂问题，就引入了d-separation的概念。通过d-seperation将DAG->moral graph就可以清楚地看出所有属性之间的条件独立性。

> This definition can be made more general by defining the "d"-separation of two nodes, where d stands for directional. Let P be a trail (that is, a collection of edges which is like a path, but each of whose edges may have any direction) from node u to v. Then P is said to be d-separated by a set of nodes Z if and only if (at least) one of the following holds:
> 
P contains a chain, u ← m ← v, such that the middle node m is in Z,
>
P contains a fork, u ← m → v, such that the middle node m is in Z, or
>
P contains an inverted fork (or collider), u → m ← v, such that the middle node m is not in Z and no descendant of m is in Z.
>
Thus u and v are said to be d-separated by Z if all trails between them are d-separated. If u and v are not d-separated, they are called d-connected.

随机变量（随即向量）之间的相依关系很容易用图表示，对于理解概率模型非常有帮助：

<img src="http://7xs6jl.com1.z0.glb.clouddn.com/LinRegPM.png">

<img src="http://7xs6jl.com1.z0.glb.clouddn.com/BLinRegPM.png">

由于BN的强大表示型，必然导致学习难度高，不仅要学习概率值，还要学习结构。就如同ANN一样，一般会结合不同问题设计不同结构，学习数值。一类简单的BN是隐马尔科夫模型（HMM）。