<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 机器学习(5) · ClT's Blog</title><meta name="description" content="机器学习(5) - ClT"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/foowaa" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about.html" target="_self" class="nav-list-link">ABOUT</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">机器学习(5)</h1><div class="post-time">Apr 11, 2016</div><div class="post-content"><h1 id="机器学习5"><a href="#机器学习5" class="headerlink" title="机器学习5"></a>机器学习5</h1><h2 id="1-kernel-machine"><a href="#1-kernel-machine" class="headerlink" title="1.kernel machine"></a>1.kernel machine</h2><p>GLM中feature表示为：<img src="http://7xs6jl.com1.z0.glb.clouddn.com/4.12.1.gif">叫做kernel machine。</p>
<p>如果为RBF kernel，则得到一个RBF NNet。误差采用二次误差，激活函数采用RBF函数。<br><img src="http://7xs6jl.com1.z0.glb.clouddn.com/4.12.2.png"><br>Architecture of a radial basis function network. An input vector x is used as input to all radial basis functions, each with different parameters. The output of the network is a linear combination of the outputs from radial basis functions.</p>
<center><img src="http://7xs6jl.com1.z0.glb.clouddn.com/4.12.3.png"></center>

<center><img src="http://7xs6jl.com1.z0.glb.clouddn.com/4.12.4.png"></center>

<p>注意，这和RBF-kernelized SVM很相似，除了采用的loss func.不同，实际上，ANN可以包含一切supervised model，ANN每一层都在做feature transformation~T(x)，BP算法在argmin erri。LM只是层数较少的（2~3层）ANN而已。</p>
<p>再注意到，如果采用uniform vote，那么这个kernel machine等同于欧氏距离的kNN算法。因为内积空间的内积度量实际也在距离度量，RBF kernel实际在度量特征的欧氏距离。</p>
<p>如何确定ci？可以使用clustering，例如k-means。</p>
<p>如果我不想使用unsupervised算法呢？最直接的方法是：</p>
<p><img src="http://7xs6jl.com1.z0.glb.clouddn.com/4.12.5.gif"></p>
<p>但是这样会导致模型的泛化能力很成问题，计算复杂度也有点高，我们希望w尽可能稀疏一点，这样就引入了sparse vector machine，SVM就是一种sparse vector machine。</p>
<h2 id="2-kernel-PCA"><a href="#2-kernel-PCA" class="headerlink" title="2.kernel PCA"></a>2.kernel PCA</h2><p>PCA方法实际是在操作Gram矩阵，而Gram矩阵与kernel有天然的联系。所以kernel PCA是最天然不过的了。对于非线性相关的数据，通过kernel将其转化为线性相关问题，这样PCA就可以奏效。<br><img src="http://7xs6jl.com1.z0.glb.clouddn.com/4.12.6.png"></p>
<p>则kernel为：</p>
<p><img src="http://7xs6jl.com1.z0.glb.clouddn.com/4.12.7.png"></p>
<p>这个kernel可以组成kernel矩阵，也是cov矩阵，再做一点变换：</p>
<p><img src="http://7xs6jl.com1.z0.glb.clouddn.com/4.12.8.gif"></p>
<p>对变换后的kernel矩阵做标准的PCA操作就可以得到kernel PCA</p>
<h2 id="4-非参统计的核方法（待）"><a href="#4-非参统计的核方法（待）" class="headerlink" title="4.非参统计的核方法（待）"></a>4.非参统计的核方法（待）</h2><h2 id="5-kernel-in-supervised-model（待）"><a href="#5-kernel-in-supervised-model（待）" class="headerlink" title="5.kernel in supervised model（待）"></a>5.kernel in supervised model（待）</h2></div></article></div></section><footer><div class="paginator"><a href="/2016/04/12/ML6/" class="prev">PRVE</a><a href="/2016/04/10/info-theory/" class="next">NEXT</a></div><div data-thread-key="2016/04/11/ML5/" data-title="机器学习(5)" data-url="http://yoursite.com/2016/04/11/ML5/" data-author-key="1" class="ds-thread"></div><script>var duoshuoQuery = {short_name:"seansun"};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
})();

</script><div class="copyright"><p>© 2016 <a href="http://yoursite.com">ClT</a>, unless otherwise noted.</p></div></footer><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>